{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"><h1> üîä Audio MNIST Tutorial - PyTorch üîä </h1></div>\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/hello-again.gif\" width=\"300\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        LA SUITE\n",
    "\n",
    "Maintenant que le traitement des donn√©es a √©t√© effectu√©, nous allons cr√©er, entra√Æner et tester notre futur mod√®le. J'esp√®re que tu as r√©vis√© ton cours sur les CNNs car c'est le m√™me type de mod√®le que nous allons cr√©er."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        LES BIBLIOTH√àQUES\n",
    "\n",
    "Comme je l'avais pr√©cis√© dans l'intro de la premi√®re partie, nous allons utiliser PyTorch pour cr√©er notre r√©seau de neurones artificiels. De plus, la biblioth√®que va aussi nous permettre de cr√©er la partie convolution de notre r√©seaux.\n",
    "\n",
    "On va aussi r√©utiliser \"matplotlib\" en plus de \"sklearn\" et \"intertools\" pour tracer et visualiser des donn√©es sous forme de graphiques afin de mieux comprendre comment fonctionne notre mod√®le.\n",
    "\n",
    "Enfin, on utilise aussi \"os\" et \"numpy\" pour charger les donn√©es trait√©es pr√©c√©demment et les utiliser dans le mod√®le."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        R√âCUP√âRATION DES DONN√âES\n",
    "        \n",
    "Tout d'abord, nous allons charger les donn√©es trait√©es dans des listes afin de pouvoir les utiliser plus tard.\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/i-have-the-data.gif\" width=\"500\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = './data'\n",
    "\n",
    "train_dir = parent_dir + '/train'\n",
    "test_dir = parent_dir + '/test'\n",
    "\n",
    "list_train_files_names = []\n",
    "list_test_files_names = []\n",
    "\n",
    "# R√©cup√©ration des chemins vers tout les fichiers\n",
    "for i in range(10):\n",
    "    path = train_dir + '/' + str(i)\n",
    "    list_train_files_names.append(os.listdir(path))\n",
    "\n",
    "for i in range(10):\n",
    "    path = test_dir + '/' + str(i)\n",
    "    list_test_files_names.append(os.listdir(path))\n",
    "\n",
    "feature_train = []\n",
    "label_train = []\n",
    "feature_test = []\n",
    "label_test = []\n",
    "\n",
    "# Chargement des donn√©es dans des tableaux de matrices\n",
    "for i in range(len(list_train_files_names)):\n",
    "    for j in range(len(list_train_files_names[i])):\n",
    "        data = loadtxt(train_dir + '/' + str(i) + '/' + list_train_files_names[i][j], delimiter=',')\n",
    "        feature_train.append(data)\n",
    "        label_train.append(i)\n",
    "\n",
    "for i in range(len(list_test_files_names)):\n",
    "    for j in range(len(list_test_files_names[i])):\n",
    "        data = loadtxt(test_dir + '/' + str(i) + '/' + list_test_files_names[i][j], delimiter=',')\n",
    "        feature_test.append(data)\n",
    "        label_test.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        DERNI√àRE MODIFICATION\n",
    "\n",
    "Comme le titre l'indique, nous n'avons pas totalement fini de modifier les donn√©es avant de les utilis√©es. En effet, il reste trois derniers d√©tails avant que nos donn√©es soit parfaites.\n",
    "\n",
    "Tout d'abord, il faut normaliser les donn√©es pour ainsi acc√©l√©rer l'entra√Ænement du mod√®le en r√©duisant le d√©calage de covariable interne. Ensuite, nous allons ajouter une dimension aux tenseurs qui va servir d'emplacement pour les futurs \"features maps\" g√©n√©r√©s par le CNN. Enfin, on modifie le type des donn√©es afin d'√™tre compatible avec celles utilis√©es par PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout d'une dimension aux tenseurs\n",
    "feature_train = np.expand_dims(feature_train, 1)\n",
    "label_train = np.array(label_train)\n",
    "\n",
    "feature_test = np.expand_dims(feature_test, 1)\n",
    "label_test = np.array(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(feature_train))\n",
    "print(len(feature_test))\n",
    "\n",
    "print(type(feature_train[0][0][0]))\n",
    "print(type(label_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(feature_train[0][0][0][0]))\n",
    "print(type(label_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification des types de variables utilis√©es\n",
    "feature_train = np.float32(feature_train)\n",
    "feature_test = np.float32(feature_test)\n",
    "label_train = np.int64(label_train)\n",
    "label_test = np.int64(label_test)\n",
    "\n",
    "print(type(feature_train[0][0][0][0]))\n",
    "print(type(label_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        CR√âATION DES DATASETS\n",
    "\n",
    "Le code pour le traitement des √©chantillons de donn√©es peut devenir d√©sordonn√© et difficile √† maintenir. Nous voulons id√©alement que notre code de dataset soit d√©coupl√© de notre code d'entra√Ænement de mod√®le pour une meilleure lisibilit√© et modularit√©. Heuresement, PyTorch fournit deux primitives de donn√©es : \"torch.utils.data.DataLoader\" et \"torch.utils.data.Dataset\" qui vous permettent d'utiliser des ensembles de donn√©es pr√©charg√©s ainsi que vos propres donn√©es. Dataset stocke les √©chantillons et leurs √©tiquettes correspondantes, et DataLoader enroule un it√©rable autour du Dataset pour permettre un acc√®s facile aux √©chantillons.\n",
    "\n",
    "Pour ce tutoriel, nous allons cr√©er des Datasets personnalis√©es. Les classes cr√©√©s doivent h√©riter de la classe Dataset et surcharger 3 fonctions:  __init__, __len__ et __getitem__.\n",
    "\n",
    "La fonction __init__ est ex√©cut√©e une fois lors de l'instanciation de l'objet Dataset. Souvent, elle permet d'initialis√©e le r√©pertoire contenant les donn√©es, le r√©pertoire des √©tiquettes si l'apprentissage est supervis√©, et des m√©thodes de transformations des donn√©es.\n",
    "\n",
    "La fonction __len__ renvoie le nombre d'√©chantillons dans notre jeu de donn√©es.\n",
    "\n",
    "La fonction __getitem__ charge et renvoie un √©chantillon de l'ensemble de donn√©es √† l'indice idx donn√©.\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/my-data.gif\" width=\"500\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation d'une classe AuioMNISTDataset\n",
    "class AudioMNISTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, features, labels, transform=None, target_transform=None):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        label = self.labels[idx]\n",
    "        feature = torch.from_numpy(feature)\n",
    "        if self.transform:\n",
    "            feature = self.transform(feature)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation de deux Datasets : un pour l'entra√Ænement du mod√®le et un pour le test\n",
    "train_dataset = AudioMNISTDataset(feature_train, label_train, transform=nn.BatchNorm1d(64))\n",
    "test_dataset = AudioMNISTDataset(feature_test, label_test, transform=nn.BatchNorm1d(64))\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation des DataLoader qui utilisent les deux Datasets cr√©√©s\n",
    "# Chaque it√©ration sur les DataLoaders renvoie un lot de train_features et train_labels (contenant respectivement batch_size=64 features et labels).\n",
    "# Parce que nous avons sp√©cifi√© shuffle=True, les donn√©es sont m√©lang√©es\n",
    "batch_size = 64;\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        CR√âATION DU MOD√àLE\n",
    "\n",
    "Maintenant que les donn√©es sont pr√™tes √† √™tre utilis√©es, nous allons cr√©er le r√©seau de neurones au c≈ìur de ce tutoriel. Avec PyTorch, les r√©seaux de neurones sont compos√©s de couches/modules qui effectuent des op√©rations sur les donn√©es. L'espace de nom torch.nn fournit tous les √©l√©ments de base dont vous avez besoin pour construire votre propre r√©seau neuronal. Chaque module dans PyTorch sous-classe le module nn.Module. Un r√©seau neuronal est un module en soi qui se compose d'autres modules (couches). Cette structure imbriqu√©e permet de construire et de g√©rer facilement des architectures complexes.\n",
    "\n",
    "Pour ce tutoriel, nous allons cr√©er un CNN (Convolutional Neural Network) pour tra√Æter nos donn√©es. /* explication de l'utilisation d'un CNN */\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/confused-travolta.gif\" width=\"500\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation de la classe contenant les couches du r√©seau de neurones\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=32,            \n",
    "                kernel_size=3,              \n",
    "                stride=1,                   \n",
    "                padding=1,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=32,              \n",
    "                out_channels=32,            \n",
    "                kernel_size=3,              \n",
    "                stride=1,                   \n",
    "                padding=1,                  \n",
    "            ),   \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 16 * 16, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 16 * 16)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation du mod√®le, de la fonction loss et de l'optimizer qui vont √™tre utilis√©s pour entra√Æner le mod√®le\n",
    "cnn = CNN()\n",
    "loss_func = nn.CrossEntropyLoss()   \n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        L'ENTRAINEMENT DU MOD√àLE\n",
    "\n",
    "Maintenant que la structure du mod√®le est d√©fini, on va passer √† son entra√Ænement (j'esp√®re que vous avez un GPU sur vous ^^). Pour entra√Æner le r√©seau, nous allons tout simplement cr√©er une fonction train() qui va faire passer un batch du Dataset d'entrainement dans le r√©seau et corriger les param√®tres du mod√®le gr√¢ce √† l'optimizer et la loss d√©finis plut√¥t.\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/train.gif\" width=\"500\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Une √©poque correspond √† un passage complet du Dataset dans le r√©seau.\n",
    "num_epochs = 3\n",
    "\n",
    "# Fonction pour entra√Æner le mod√®le\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    \n",
    "    # Indique √† votre mod√®le que vous √™tes en train de le former. Ainsi, les couches comme dropout, batchnorm etc. qui se comportent diff√©remment dans les proc√©dures d'entra√Ænement et de test savent ce qui se passe et peuvent donc se comporter en cons√©quence.\n",
    "    cnn.train()\n",
    "    \n",
    "    total_step = len(loaders['train'])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            \n",
    "            # R√©cup√©ration de la pr√©diction d'un batch de donn√©e\n",
    "            output = cnn(images) \n",
    "            # Calcul de la fonction co√ªt de la pr√©diction            \n",
    "            loss = loss_func(output, labels)\n",
    "            # R√©initialise les gradients \n",
    "            optimizer.zero_grad()           \n",
    "            # Backpropagation et calcul des gradients \n",
    "            loss.backward()    \n",
    "            # Application des gradients pour corriger les param√®tres du mod√®le          \n",
    "            optimizer.step() \n",
    "\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "\n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, total_step, total_step, loss.item()))\n",
    "\n",
    "train(num_epochs, cnn, loaders)\n",
    "\n",
    "print('Model has been trained {} times with {} datas'.format(num_epochs, len(train_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        LE TEST DU MOD√àLE\n",
    "\n",
    "Et voil√†, nous venons de cr√©er et d'entra√Æner un r√©seau de neurones. Mais maintenant, nous devons tester son efficacit√©. Dans notre cas, le mod√®le r√©soud un probl√®me de classification. Nous pouvons donc simplement calculer le taux de r√©ussite de pr√©diction sur le Dataset de test afin de nous faire une id√©e sur son efficacit√©.\n",
    "\n",
    "Bien s√ªr, nous pouvons faire d'autres tests afin de v√©rifier d'autres aspects du mod√®le. Par exemple cr√©er une matrice de confusion √† partir des pr√©dictions des donn√©es d'entra√Ænements. Cette matrice peut se r√©v√©ler tr√®s pratique pour conna√Ætre les faiblesses de notre mod√®le, comme la classe que le mod√®le √† le plus de mal √† pr√©dire.\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/test.gif\" width=\"500\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour tester le mod√®le\n",
    "def test():\n",
    "    all_preds = torch.tensor([])\n",
    "    all_labels = torch.tensor([])\n",
    "    cnn.eval()\n",
    "    accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output = cnn(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy += (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "\n",
    "            all_preds = torch.cat((all_preds, pred_y),dim=0)\n",
    "            all_labels = torch.cat((all_labels, labels),dim=0)\n",
    "\n",
    "    accuracy /= len(loaders['test'])\n",
    "    print('Test Accuracy of the model on the {} test : {:.2f}%'.format(len(test_dataset), (accuracy*100)))\n",
    "    return all_labels, all_preds\n",
    "\n",
    "all_labels, all_preds = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour afficher la matrice de confucion des donn√©es test\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    \n",
    "all_labels = all_labels.type(torch.int64)\n",
    "all_preds = all_preds.type(torch.int64)\n",
    "confusion_mat = confusion_matrix(all_labels, all_preds)\n",
    "labels = np.array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(confusion_mat, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        SAUVEGARDE DU MOD√àLE\n",
    "\n",
    "Enfin, maintenant que nous avons v√©rifi√© que le mod√®le est tr√®s performant, nous pouvons le sauvegarder afin de l'utiliser plus tard.\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/victory.gif\" width=\"500\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du mod√®le\n",
    "torch.save(cnn.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du mod√®le\n",
    "saved_cnn = CNN()\n",
    "saved_cnn.load_state_dict(torch.load(\"model.pth\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73af3793c810b2a3f8bd1cb637bb1a8b95e3ec97104733af0e6466340a9bb654"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
