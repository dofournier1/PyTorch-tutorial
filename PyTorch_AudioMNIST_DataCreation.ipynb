{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"><h1> üîä Audio MNIST Tutorial - PyTorch üîä </h1></div>\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/5Tz.gif\" width=\"300\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        WELCOME !\n",
    "\n",
    "Bonjour et bienvenue dans ce tuto qui va t'apprendre √† utiliser tout un tas d'outils utiles pour cr√©er une IA capable de d√©terminer le chiffre qu'une personne dira.\n",
    "\n",
    "Avant toute chose, pour suivre ce tuto, il te faut un minimum de connaissance dans le traitement audio, le fonctionnement des r√©seaux de neurones (plus particuli√®rement les CNNs) et Python, √©videmment. Donc si tu n'as pas fait les tutos concernant ces domaines avant celui-ci, je te conseille vivement d'aller les faire, car je n'ai pas l'intention de r√© expliquer ce qui a d√©j√† √©t√© expliqu√©.\n",
    "\n",
    "Si tu lis cette ligne, je suppose que tu as les connaissances n√©cessaires pour commencer ce tuto ... Ou alors que tu t'en fiche ... Bah, peu importe, dans tous les cas, c'est parti !\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/32R.gif\" width=\"400\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        LE CONTENU\n",
    "\n",
    "Pour bien d√©marrer ce tutoriel, je vais tout d'abord t'expliquer comment celui-ci va se d√©rouler.\n",
    "\n",
    "En premier lieu, sache que ce tuto est d√©coup√© en deux parties. La premi√®re, celle o√π tu te trouves, va t'aider √† comprendre que la cr√©ation d'une IA ne se limite pas qu'√† ... la cr√©ation de l'IA. Attends, je vais t'expliquer.\n",
    "\n",
    "Comme tu dois s√ªrement le savoir, pour cr√©er une IA en utilisant la technologie du deep learning, il faut trois grandes √©tapes : cr√©er le mod√®le d'apprentissage de l'IA, la faire apprendre et la tester. Jusque-l√†, normalement, je ne t'ai pas perdu. Et, o√π je veux en venir, c'est que parmi ces trois grandes √©tapes, les deux derni√®res supposent quelques choses d'importants. C'est qu'ils nous faut des donn√©es. Beaucoup, beaucoup de donn√©es. Et toutes ces donn√©es, ils faut les cr√©er et les traiter pour pouvoir les utiliser. Et ce travail sur ces donn√©es, nous allons le faire dans la premi√®re partie de ce tuto.\n",
    "\n",
    "La seconde partie, comme tu dois t'en douter, va te permettre de comprendre le c≈ìur du sujet. La cr√©ation, l'apprentissage et le test d'un mod√®le.\n",
    "\n",
    "Il existe plusieurs technologies sur Python qui permettent de faire du deep learning (cr√©er des mod√®les, les entra√Æner, ect...). Mais ce tuto sera consacr√© √† l'utilisation de PyTorch. PyTorch est une biblioth√®que open source de machine learning qui s'appuie sur Torch d√©velopp√©e par Facebook.\n",
    "\n",
    "PyTorch permet d'effectuer les calculs tensoriels n√©cessaires notamment pour le deep learning. Ces calculs sont optimis√©s et effectu√©s soit par le processeur (CPU) soit, lorsque c'est possible, par un processeur graphique (GPU) supportant CUDA.\n",
    "\n",
    "PyTorch permet de :\n",
    "\n",
    "- manipuler des tenseurs, de les √©changer facilement avec Numpy et d'effectuer des calculs efficaces sur CPU ou GPU (par exemple, des produits de matrices ou des convolutions);\n",
    "- calculer des gradients pour appliquer facilement des algorithmes d'optimisation par descente de gradient. PyTorch utilise la biblioth√®que autograd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "        LES DONN√âES\n",
    "\n",
    "Maintenant que tu sais ce qui t'attend, on va se lancer dans le traitement des donn√©es. Comme on n'est pas des monstres, on a quand m√™me pr√©par√© le terrain en fournissant des donn√©es brutes pour ce tutoriel. \n",
    "\n",
    "Donc la cr√©ation des donn√©es, c'est fait. Mais comme je viens de le dire, ce sont des donn√©es brutes, donc on va devoir les trait√©s pour les rendre utilisables dans la deuxi√®me partie du tuto. Ces donn√©es, tu peux les trouver dans le dossier AudioMNIST_data. Ce sont des enregistrements audio de 60 personnes diff√©rentes, rang√©s dans 60 dossiers diff√©rents num√©rot√©es de 01 √† 60. Chaque personne a permis de cr√©er 500 enregistrements diff√©rents avec, √† chaque fois, 50 audios pour chaque chiffre de 0 √† 9 en anglais. Le nom des audios permet de retrouver leurs origines, par exmple l'audio 4_01_14.wav correspond au 14√®me enregistrements de la personne 01 qui prononce le chiffre 4. Au total, cela nous fait 30 000 enregistrements pour notre application. \n",
    "\n",
    "On peut aussi trouver dans ce dossier, le fichier audioMNIST_meta.txt qui nous donne des informations sur chaque personne et leurs conditions d'enregistrements. Vu que nous voulons classer les enregistrements en fonction du chiffre qui est prononc√©, ce fichier ne nous sera pas utile.\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/gee-data-entry.gif\" width=\"300\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        LES BIBLIOTH√àQUES\n",
    "\n",
    "Il existe √©norm√©ment de biblioth√®ques en Python capable de faire du traitement de donn√©es comme Pandas, NumPy, Matplotlib, SciPy, SciKit-Learn, ect... Et pour ce tuto, nous allons utiliser les deux plus simples √† prendre en main, NumPy et Matplotlib.\n",
    "\n",
    "- Numpy est une biblioth√®que qui est destin√©e √† manipuler des matrices ou tableaux multidimensionnels ainsi que des fonctions math√©matiques op√©rant sur ces tableaux.\n",
    "\n",
    "- Matplotlib, quant √† elle, est plut√¥t destin√©e √† tracer et visualiser des donn√©es sous forme de graphiques. Elle peut √™tre combin√©e avec les biblioth√®ques NumPy et SciPy. Elle nous sera tr√®s utile pour visualiser et comprendre les donn√©es qu'on va traiter.\n",
    "\n",
    "De plus, nous allons utiliser librosa que vous avez d√©j√† utiliser lors des tutos pr√©c√©dents et qui va nous servir √† transformer les audios en donn√©es plus utiles pour notre mod√®le.\n",
    "\n",
    "Nous allons aussi utiliser d'autres biblioth√®ques comme cv2 qui va √™tre utilis√© pour du traitement d'images, et random qui va nous permettre de g√©n√©rer des nombres pseudos-randoms.\n",
    "\n",
    "Et enfin, nous allons aussi utiliser le module OS qui fournit des fonctions d‚Äôinteraction avec le syst√®me d‚Äôexploitation. Ce module nous sera utile pour r√©cup√©rer les donn√©es brutes dans le programme.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        R√âCUP√âRATION DES DONN√âES\n",
    "        \n",
    "Tout d'abord, nous allons r√©cup√©rer les chemins relatifs de tous les enregistrements audios. Nous allons les stocker dans un dictionnaire afin de leur associ√©, en m√™me temps que leur stockage, une valeur \"train\" ou \"test\" qui va d√©finir si le fichier associ√© √† ce chemin sera utilis√© plus tard pour entra√Æner le mod√®le ou tester le mod√®le. En recherchant sur le net les diff√©rents projets de deep learning disponibles, on peut constater que pour un jeu de donn√©e d√©finit, 80% d'entre elle sont utilis√©es pour l'entra√Ænement, et 20% pour le test. Et c'est exactement ce que nous allons faire ici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nom du fichier dans lequel les donn√©es brutes sont stock√©es\n",
    "data_dir = './AudioMNIST_data/'\n",
    "\n",
    "# Tableau qui va contenir tout les chemins vers toutes les donn√©es brutes\n",
    "file_names = {}\n",
    "\n",
    "test_indices = random.sample(range(0, 30000), int((30000*20)/100))\n",
    "test_indices.sort()\n",
    "\n",
    "i = j = 0\n",
    "\n",
    "for dirname, _, filenames in os.walk(data_dir):\n",
    "    for filename in filenames:\n",
    "        file_label = filename[0]\n",
    "        # Si le fichier est audioMNIST_meta.txt alors on ne sauvegarde pas son chemin\n",
    "        if file_label == 'a':\n",
    "            pass\n",
    "        else:\n",
    "            if j < int((30000*20)/100) and i == test_indices[j]:\n",
    "                file_names[dirname + '/' + filename] = \"test\"\n",
    "                j += 1\n",
    "            else:\n",
    "                file_names[dirname + '/' + filename] = \"train\"\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        TRA√éTEMENT DES DONN√âES\n",
    "\n",
    "Une fois la r√©cup√©ration et le trie fait, nous allons tra√Æter ces donn√©es. Il faut savoir qu'un fichier audio apporte beaucoup moins d'informations dans le domaine temporelle que le domaine fr√©quentielle. C'est pour cela que nous allons transformer les donn√©es brutes en mel-spectrogrammes afin de r√©cup√©rer le maximum d'information utile pour le futur mod√®le. \n",
    "\n",
    "Ces mel-spectrogrammes vont √™tre stock√©s dans 2 tableaux diff√©rents afin de diff√©renci√©s les donn√©es pour l'entra√Ænement et les donn√©es pour le test. \n",
    "\n",
    "Et enfin, nous cr√©ons en parall√®les 2 autres tableaux, un pour les donn√©es d'entra√Ænement et un pour les donn√©es de test, qui vont stock√©s la valeur des chiffres prononc√©s dans l'audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention ! L'ex√©cution de cette partie du code peut √™tre particuli√®rement longue ! (15-20 min)\n",
    "labels = np.array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "img_size = 64\n",
    "cpt = 0\n",
    "feature_train = []\n",
    "label_train = []\n",
    "feature_test = []\n",
    "label_test = []\n",
    "\n",
    "for cle, valeur in file_names.items():\n",
    "\n",
    "    # R√©cup√©ration de la valeur du chiffre prononc√© qui est stock√©s dans le nom du fichier\n",
    "    label = int(cle[21])\n",
    "    \n",
    "    # Chargement du fichier audio\n",
    "    x , sr = librosa.load(cle)\n",
    "\n",
    "    # STFT sur le fichier audio afin de cr√©er un spectrogramme\n",
    "    spectrogram = librosa.stft(x)\n",
    "\n",
    "    # Cr√©ation du mel-spectrogram\n",
    "    sgram_mag, _ = librosa.magphase(spectrogram)\n",
    "    mel_scale_sgram = librosa.feature.melspectrogram(S=sgram_mag, sr=sr)\n",
    "    mel_sgram = librosa.amplitude_to_db(mel_scale_sgram, ref=np.min)\n",
    "\n",
    "    # Redimensionnement du mel-spectrogram afin que les donn√©es soit stock√©s dans une matrice carr√©\n",
    "    img_arr = mel_sgram[...,::-1]\n",
    "    resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "    \n",
    "    if (valeur == \"test\"):\n",
    "        feature_test.append(resized_arr)\n",
    "        label_test.append(label)\n",
    "    else :\n",
    "        feature_train.append(resized_arr)\n",
    "        label_train.append(label)\n",
    "    \n",
    "    cpt += 1\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    prog = round(cpt * 100 / 30000, 2)\n",
    "\n",
    "    print(\"Progression : \", round(cpt * 100 / 30000, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        AFFICHAGE DES DONN√âES TRA√éT√âES\n",
    "\n",
    "Gr√¢ce √† matplotlib, nous allons afficher les mel-spectrograms afin de v√©rifier si aucune erreur n'a eu lieu lors du traitement et pour aussi comprendre les donn√©es que nous venons de cr√©er.\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/i-know.gif\" width=\"500\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(feature_train[0])\n",
    "plt.title(labels[label_train[0]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(feature_train[-1])\n",
    "plt.title(labels[label_train[-1]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        SAUVEGARDE DES DONN√âES\n",
    "\n",
    "Maintenant que le traitement a √©t√© fait, il ne nous reste plus qu'√† sauvegarder le travail fait. Pour sauvegarder les donn√©es, nous allons cr√©er un fichier \"data\" qui va contenir un fichier \"train\" et \"test\" afin de s√©parer les donn√©es pour plus tard. Ensuite, dans chacun de ces fichiers, nous cr√©ons 10 nouveaux fichiers num√©rot√©s de 0 √† 9 afin de s√©parer les donn√©es en fonction du chiffre enregistr√© dans l'audio. Et enfin, dans les fichiers num√©rot√©s, on enregistre les diff√©rents mel-spectrogrammes en format CSV qui est un format facile √† mettre en place et suffisant pour les donn√©es que nous avons.\n",
    "\n",
    "<div style=\"text-align: center; margin-top: 50px\"> <img src=\"./images/meme-power-rangers.gif\" width=\"500\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation des dossiers data, train et test\n",
    "parent_dir = './data'\n",
    "os.mkdir(parent_dir)\n",
    "\n",
    "train_dir = parent_dir + '/train'\n",
    "test_dir = parent_dir + '/test'\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# Cr√©ation des dossiers de 0 √† 9 dans les dossiers train et test\n",
    "for i in range(len(labels)):\n",
    "  file_dir = train_dir + '/' + labels[i]\n",
    "  os.mkdir(file_dir)\n",
    "  file_dir = test_dir + '/' + labels[i]\n",
    "  os.mkdir(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des mel-spectrogram au format CSV dans le dossier train\n",
    "for i in range(len(feature_train)):\n",
    "  data = feature_train[i]\n",
    "  path = train_dir + '/' + str(label_train[i]) + '/' + str(i) + '.csv'\n",
    "  savetxt(path, data, delimiter=',')\n",
    "  clear_output(wait=True)\n",
    "  print(\"Progression de la sauvegarde des donn√©es d'entra√Ænement : \", round((i+1) * 100 / len(feature_train), 2), \"%\")\n",
    "\n",
    "# Sauvegarde des mel-spectrogram au format CSV dans le dossier test\n",
    "for i in range(len(feature_test)):\n",
    "  data = feature_test[i]\n",
    "  path = test_dir + '/' + str(label_test[i]) + '/' + str(i) + '.csv'\n",
    "  savetxt(path, data, delimiter=',')\n",
    "  clear_output(wait=True)\n",
    "  print(\"Progression de la sauvegarde des donn√©es d'entra√Ænement : 100 %\")\n",
    "  print(\"Progression de la sauvegarde des donn√©es de test : \", round((i+1) * 100 / len(feature_test), 2), \"%\")\n",
    "\n",
    "print(\"Donn√©es sauvegard√©es\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73af3793c810b2a3f8bd1cb637bb1a8b95e3ec97104733af0e6466340a9bb654"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
